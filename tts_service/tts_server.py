from flask import Flask, request, send_file
import torch
import io
import numpy as np
from scipy.io import wavfile

app = Flask(__name__)

print("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ Silero TTS v5...")
device = "cpu"
model, _ = torch.hub.load(
    repo_or_dir='snakers4/silero-models',
    model='silero_tts',
    language='ru',
    speaker='v5_ru'  # ‚úÖ –ù–û–í–´–ô v5 ‚Äî –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π!
)
speakers = model.speakers
print(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–ø–∏–∫–µ—Ä—ã: {speakers}")
print("–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ: 'xenia' (–º—è–≥–∫–∏–π –∂–µ–Ω—Å–∫–∏–π), 'eugene' (–º—É–∂—Å–∫–æ–π –∂–∏–≤–æ–π)")

def preprocess_text(text):
    """üéØ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ—Å–æ–¥–∏–∏ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏"""
    if not text:
        return ""

    # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—ã –ø–æ—Å–ª–µ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    text = text.replace('.', '. ').replace('!', '! ').replace('?', '? ')
    text = text.replace('..', '...').replace('...', '... ')

    # ‚úÖ –†–∞–∑–±–∏–≤–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    if len(text) > 120:
        words = text.split()
        text = ' '.join(words[:20]) + '...'

    # ‚úÖ –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    return ' '.join(text.split())

@app.route('/synthesize', methods=['POST'])
def synthesize():
    data = request.get_json()
    text = data.get('text', '').strip()
    speaker = data.get('speaker', 'xenia')  # ‚úÖ –õ—É—á—à–∏–π –ø–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏!

    if not text:
        return {"error": "–¢–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π"}, 400

    # ‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
    text = preprocess_text(text)
    print(f"üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: '{text}' (—Å–ø–∏–∫–µ—Ä: {speaker})")

    # ‚úÖ –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Silero v5 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
    audio = model.apply_tts(
        text=text,
        speaker=speaker,
        sample_rate=48000,
        put_accent=True,           # ‚úÖ –ê–≤—Ç–æ-—É–¥–∞—Ä–µ–Ω–∏—è
        put_yo=True,               # ‚úÖ –Å –≤—Å–µ–≥–¥–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
        put_stress_homo=True,      # ‚úÖ v5: –≥–æ–º–æ–≥—Ä–∞—Ñ—ã —Å —É–¥–∞—Ä–µ–Ω–∏—è–º–∏
        put_yo_homo=True           # ‚úÖ v5: –Å –≤ –≥–æ–º–æ–≥—Ä–∞—Ñ–∞—Ö
    )

    # ‚úÖ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [-1,1] ‚Üí int16
    audio = torch.clamp(audio, -1.0, 1.0)
    mono = (audio.numpy() * 32767).astype(np.int16)

    # ‚úÖ –ú–æ–Ω–æ ‚Üí —Å—Ç–µ—Ä–µ–æ (L=R –¥–ª—è Discord)
    stereo = np.stack([mono, mono], axis=1)  # shape: (N_samples, 2_channels)

    # ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: BIG-ENDIAN –¥–ª—è Discord/JDA!
    stereo_big_endian = stereo.astype('>i2')  # NumPy 2.0 —Å–æ–≤–º–µ—Å—Ç–∏–º–æ

    # ‚úÖ Raw PCM –±–∞–π—Ç—ã (48kHz, 16bit, stereo, BIG-ENDIAN)
    pcm_bytes = stereo_big_endian.tobytes()

    # ‚úÖ –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ –ø–∞–∫–µ—Ç–∞–º Discord (3840 –±–∞–π—Ç = 20ms)
    packet_size = 3840
    aligned_len = (len(pcm_bytes) // packet_size) * packet_size
    pcm_bytes = pcm_bytes[:aligned_len]

    print(f"üéµ PCM BIG-ENDIAN: {len(pcm_bytes)} bytes, {len(pcm_bytes)//packet_size} –ø–∞–∫–µ—Ç–æ–≤")

    buffer = io.BytesIO(pcm_bytes)
    buffer.seek(0)

    # ‚úÖ –ì–æ—Ç–æ–≤—ã–π Discord PCM (–±–µ–∑ WAV-–æ–±—ë—Ä—Ç–∫–∏!)
    return send_file(
        buffer,
        mimetype='application/octet-stream',
        as_attachment=True,
        download_name='speech.pcm'
    )

@app.route('/speakers', methods=['GET'])
def get_speakers():
    """üîç –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤"""
    return {"speakers": list(speakers), "recommended": ["xenia", "eugene", "aidar"]}

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
